{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = r\"D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\"\n",
    "des_path = r\"D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar_test\"\n",
    "\n",
    "test40_img = glob.glob(os.path.join(img_path,'*40.jpg'))\n",
    "test41_img = glob.glob(os.path.join(img_path,'*41.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatar41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarblur41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarbrightness41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarcolorjitter41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarcontrast41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarhflip41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avataropacity41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarrandomnoise41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarrotate2041.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarrotate3041.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarrotate4041.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarrotate41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarrotate4541.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarsaturation41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarsharpen41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels00241.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels00341.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels0041.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels00441.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels00541.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels00641.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels00741.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels00841.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels00941.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels0141.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarshufflepixels41.jpg', 'D:\\\\python\\\\gitdatabase\\\\transformer\\\\vit-pytorch\\\\examples\\\\avatar\\\\avatarvflip41.jpg']\n"
     ]
    }
   ],
   "source": [
    "print(test41_img)\n",
    "for i in test41_img:\n",
    "    shutil.move(i,os.path.join(des_path,i.split(\"\\\\\")[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\vit\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda\\envs\\vit\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "D:\\Anaconda\\envs\\vit\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "D:\\Anaconda\\envs\\vit\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\vit\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models.vision_transformer as vit\n",
    "model = vit.vit_b_16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vit.vit_b_16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import csv\n",
    "import glob\n",
    "\n",
    "path = r\"D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\"\n",
    "test_img = glob.glob(os.path.join(path,'*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarbrightness22.jpg\n",
      "10 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarbrightness31.jpg\n",
      "20 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarbrightness40.jpg\n",
      "30 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarcolorjitter10.jpg\n",
      "40 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarcolorjitter2.jpg\n",
      "50 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarcolorjitter29.jpg\n",
      "60 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarcolorjitter38.jpg\n",
      "70 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarcolorjitter8.jpg\n",
      "80 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarcontrast17.jpg\n",
      "90 ### D:\\python\\gitdatabase\\transformer\\vit-pytorch\\examples\\avatar\\avatarcontrast26.jpg\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "outs=[]\n",
    "names =[]\n",
    "for idx,i in enumerate(test_img[100:200]):\n",
    "    if not (idx%10):\n",
    "        print(idx,\"###\",i)\n",
    "    img = Image.open(i)\n",
    "    img_transformed = transform(img)\n",
    "    data = torch.stack([img_transformed,],dim=0)\n",
    "    out = model(data)\n",
    "    outs.append(out)\n",
    "    names.append(i.split(\"\\\\\")[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "with open(\"test200.csv\",\"ab\") as file:\n",
    "    for i in outs:\n",
    "        np.savetxt(file,i.detach().numpy(),delimiter=\",\",fmt=\"%.4f\")\n",
    "with open(\"test_name200.csv\",\"w\",newline=\"\") as files:\n",
    "    writer = csv.writer(files)\n",
    "    for i in names:\n",
    "        writer.writerow([i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
